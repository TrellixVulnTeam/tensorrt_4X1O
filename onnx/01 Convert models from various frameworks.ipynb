{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Convert models from various frameworks\n",
    "* [1. Caffe to ONNX](#1.-Caffe-to-ONNX)\n",
    "* [2. Keras to ONNX](#2.-Keras-to-ONNX)\n",
    "* [3. TensorFlow to ONNX](#3.-TensorFlow-to-ONNX)\n",
    "* [4. PyTorch to ONNX](#4.-PyTorch-to-ONNX)\n",
    "* [5. Caffe2 to ONNX](#5.-Caffe2-to-ONNX)\n",
    "* [6. MXNet to ONNX](#6.-MXNet-to-ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q onnx==1.7.0 coremltools onnxmltools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Caffe to ONNX\n",
    "https://github.com/BVLC/caffe/wiki/Model-Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 獲得預訓練模型 (mobilenet)\n",
    "# !wget -q https://github.com/shicai/MobileNet-Caffe/blob/master/mobilenet.caffemodel?raw=true -O Caffe/model.caffemodel\n",
    "# !wget -q https://raw.githubusercontent.com/shicai/MobileNet-Caffe/master/mobilenet_deploy.prototxt -O Caffe/model.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.0.0 detected. Last version known to be fully compatible is 1.14.0 .\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import coremltools\n",
    "import onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_path = \"Caffe/model.caffemodel\"\n",
    "proto_path = \"Caffe/model.prototxt\"\n",
    "onnx_path = \"Caffe/model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:onnxmltools:The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "coreml_model = coremltools.converters.caffe.convert((caffe_path, proto_path))\n",
    "onnx_model = onnxmltools.convert_coreml(coreml_model)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx.save(onnx_model, onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras to ONNX\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 獲得預訓練模型 (mobilenet)，並將模型存成 h5 檔\n",
    "# from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "# model = MobileNet(weights='imagenet', include_top=True)\n",
    "# model.save('Keras/model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the onnxmltools modoule to convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxmltools\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_path = 'Keras/model.h5'\n",
    "onnx_path = 'Keras/model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "tf executing eager_mode: True\n",
      "INFO:keras2onnx:tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "INFO:keras2onnx:tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 248 -> 63\n",
      "INFO:keras2onnx:The ONNX operator number change on the optimization: 248 -> 63\n"
     ]
    }
   ],
   "source": [
    "keras_model = load_model(keras_path)\n",
    "onnx_model = onnxmltools.convert_keras(keras_model)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx.save(onnx_model, onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the keras2onnx modoule to convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q keras2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import keras2onnx\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_path = 'Keras/model.h5'\n",
    "onnx_path = 'Keras/model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "tf executing eager_mode: True\n",
      "INFO:keras2onnx:tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "INFO:keras2onnx:tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 248 -> 63\n",
      "INFO:keras2onnx:The ONNX operator number change on the optimization: 248 -> 63\n"
     ]
    }
   ],
   "source": [
    "keras_model = load_model(keras_path)\n",
    "onnx_model = keras2onnx.convert_keras(keras_model)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "keras2onnx.save_model(onnx_model, onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow to ONNX\n",
    "https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 獲得預訓練模型 (tensorflow 1.x mobilenet)\n",
    "# !wget -P TensorFlow http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz\n",
    "# !tar zxvf TensorFlow/mobilenet_v1_1.0_224.tgz -C TensorFlow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 獲得預訓練模型 (tensorflow 2.x mobilenet)\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "# model = MobileNet(weights='imagenet', include_top=True)\n",
    "# # Save to SavedModel directory\n",
    "# tf.saved_model.save(model, 'TensorFlow/saved_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert with SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-29 18:11:58,247 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2020-10-29 18:12:03,685 - INFO - Signatures found in model: [serving_default].\n",
      "2020-10-29 18:12:03,686 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:413: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2020-10-29 18:12:04,530 - WARNING - From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:413: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2020-10-29 18:12:05,451 - INFO - Using tensorflow=2.0.0, onnx=1.7.0, tf2onnx=1.7.1/796841\n",
      "2020-10-29 18:12:05,451 - INFO - Using opset <onnx, 8>\n",
      "2020-10-29 18:12:06,269 - INFO - Computed 0 values for constant folding\n",
      "2020-10-29 18:12:08,485 - INFO - Optimizing ONNX model\n",
      "2020-10-29 18:12:09,180 - INFO - After optimization: BatchNormalization -27 (27->0), Const -90 (152->62), Gather +1 (0->1), Identity -6 (6->0), Reshape +2 (2->4), Transpose -108 (110->2), Unsqueeze -4 (6->2)\n",
      "2020-10-29 18:12:09,215 - INFO - \n",
      "2020-10-29 18:12:09,215 - INFO - Successfully converted TensorFlow model ./TensorFlow/saved_model to ONNX\n",
      "2020-10-29 18:12:09,238 - INFO - ONNX model is saved at ./TensorFlow/model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert \\\n",
    "        --saved-model ./TensorFlow/saved_model \\\n",
    "        --output ./TensorFlow/model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert with frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mobilenet_v1_1.0_224\n",
      "Input: input\n",
      "Output: MobilenetV1/Predictions/Reshape_1\n"
     ]
    }
   ],
   "source": [
    "!head TensorFlow/mobilenet_v1_1.0_224_info.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:146: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "2020-10-29 18:12:12,869 - WARNING - From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:146: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2020-10-29 18:12:12,870 - WARNING - From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "2020-10-29 18:12:12,890 - INFO - Froze 0 variables.\n",
      "INFO:tensorflow:Converted 0 variables to const ops.\n",
      "2020-10-29 18:12:12,913 - INFO - Converted 0 variables to const ops.\n",
      "2020-10-29 18:12:13,439 - INFO - Using tensorflow=2.0.0, onnx=1.7.0, tf2onnx=1.7.1/796841\n",
      "2020-10-29 18:12:13,439 - INFO - Using opset <onnx, 8>\n",
      "2020-10-29 18:12:14,238 - INFO - Computed 0 values for constant folding\n",
      "2020-10-29 18:12:16,298 - INFO - Optimizing ONNX model\n",
      "2020-10-29 18:12:17,092 - INFO - After optimization: BatchNormalization -27 (27->0), Cast -1 (3->2), Const -81 (138->57), Identity -2 (2->0), Transpose -111 (112->1)\n",
      "2020-10-29 18:12:17,117 - INFO - \n",
      "2020-10-29 18:12:17,117 - INFO - Successfully converted TensorFlow model ./TensorFlow/mobilenet_v1_1.0_224_frozen.pb to ONNX\n",
      "2020-10-29 18:12:17,139 - INFO - ONNX model is saved at ./TensorFlow/model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert \\\n",
    "        --input ./TensorFlow/mobilenet_v1_1.0_224_frozen.pb \\\n",
    "        --inputs input:0 \\\n",
    "        --outputs MobilenetV1/Predictions/Reshape_1:0 \\\n",
    "        --output ./TensorFlow/model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyTorch to ONNX\n",
    "https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.4.0 torchvision==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 獲得預訓練模型 (mobilenet_v2)，並將模型存成 pth 檔\n",
    "# model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "# torch.save(model.state_dict(), 'PyTorch/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import torch.onnx\n",
    "print(torch.__version__)\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_path = \"PyTorch/model.pth\"\n",
    "onnx_path = \"PyTorch/model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "model = torchvision.models.mobilenet_v2(pretrained=False)\n",
    "state_dict = torch.load(torch_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_input, onnx_path)\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Caffe2 to ONNX\n",
    "https://github.com/facebookarchive/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 獲得預訓練模型 (squeezenet)\n",
    "#!cd Caffe2; python -m caffe2.python.models.download squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from caffe2.python.onnx.frontend import caffe2_net_to_onnx_model\n",
    "from caffe2.proto import caffe2_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_path = \"Caffe2/predict_net.pb\"\n",
    "init_path = \"Caffe2/init_net.pb\"\n",
    "onnx_path = \"Caffe2/model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = onnx.TensorProto.FLOAT\n",
    "data_shape = (1, 3, 224, 224)\n",
    "value_info = {\"data\": (data_type, data_shape)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_net = caffe2_pb2.NetDef()\n",
    "with open(predict_path, \"rb\") as f:\n",
    "    predict_net.ParseFromString(f.read())\n",
    "    \n",
    "init_net = caffe2_pb2.NetDef()\n",
    "with open(init_path, \"rb\") as f:\n",
    "    init_net.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_net.name == \"\":\n",
    "    predict_net.name = \"ModelNameHere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = caffe2_net_to_onnx_model(\n",
    "    predict_net,\n",
    "    init_net,\n",
    "    value_info,\n",
    ")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx.save(onnx_model, onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MXNet to ONNX\n",
    "https://cv.gluon.ai/model_zoo/classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: tf2onnx 1.7.1 has requirement onnx>=1.4.1, but you'll have onnx 1.2.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 安裝完 onnx 1.2.1 版本後須重啟 kernel \n",
    "!pip install -q onnx==1.2.1\n",
    "!pip install -q mxnet --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 獲得預訓練模型 (resnet18)\n",
    "# import mxnet as mx\n",
    "# path='http://data.mxnet.io/models/imagenet/'\n",
    "# [mx.test_utils.download(path+'resnet/18-layers/resnet-18-0000.params', \n",
    "#                         fname='model-0000.params', dirname='MXNet'),\n",
    "#  mx.test_utils.download(path+'resnet/18-layers/resnet-18-symbol.json',\n",
    "#                         fname='model-symbol.json', dirname='MXNet')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "print(onnx.__version__)\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet.contrib import onnx as onnx_mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_path = 'MXNet/model-symbol.json'\n",
    "params_path = 'MXNet/model-0000.params'\n",
    "onnx_path = 'MXNet/model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,224,224)\n",
    "converted_model_path = onnx_mxnet.export_model(\n",
    "    sym_path, \n",
    "    params_path, \n",
    "    [input_shape], \n",
    "    np.float32, \n",
    "    onnx_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load onnx model and check it\n",
    "onnx_model = onnx.load(converted_model_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
